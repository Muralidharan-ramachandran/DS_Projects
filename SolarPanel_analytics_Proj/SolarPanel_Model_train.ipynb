{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUC0UIulcSH0",
        "outputId": "92e3a274-ec20-48e2-ad0d-285f36d3015c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APhl--AUf2a6",
        "outputId": "97a82d2d-21f1-40ca-e890-522c7a64b8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 743 images belonging to 6 classes.\n",
            "Found 182 images belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 725ms/step - accuracy: 0.2800 - loss: 1.8839 - val_accuracy: 0.5440 - val_loss: 1.2629 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 812ms/step - accuracy: 0.5312 - loss: 1.1227 - val_accuracy: 0.6209 - val_loss: 1.0515 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 665ms/step - accuracy: 0.6709 - loss: 0.8322 - val_accuracy: 0.6429 - val_loss: 0.9199 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 660ms/step - accuracy: 0.6632 - loss: 0.8386 - val_accuracy: 0.7253 - val_loss: 0.8257 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 655ms/step - accuracy: 0.6756 - loss: 0.7719 - val_accuracy: 0.7088 - val_loss: 0.8001 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.7480 - loss: 0.6366\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 745ms/step - accuracy: 0.7481 - loss: 0.6367 - val_accuracy: 0.6978 - val_loss: 0.9164 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 750ms/step - accuracy: 0.7842 - loss: 0.6042 - val_accuracy: 0.7253 - val_loss: 0.7676 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 743ms/step - accuracy: 0.7965 - loss: 0.5506 - val_accuracy: 0.7308 - val_loss: 0.7791 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 723ms/step - accuracy: 0.8010 - loss: 0.5855 - val_accuracy: 0.7473 - val_loss: 0.7332 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 651ms/step - accuracy: 0.8128 - loss: 0.5338 - val_accuracy: 0.7418 - val_loss: 0.7104 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = '/content/drive/MyDrive/SolarGuard/Solar_Panel_Dataset/Faulty_solar_panel'\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "# Data Generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=2,\n",
        "    factor=0.5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "\n",
        "# Model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(6, activation='softmax')  # 6 classes\n",
        "])\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS,class_weight=class_weights,callbacks=[lr_scheduler])\n",
        "\n",
        "# Save Model\n",
        "model.save('/content/drive/MyDrive/SolarGuard/mobilenetv2_solar.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Get true labels and predictions\n",
        "val_generator.reset()\n",
        "pred_probs = model.predict(val_generator, verbose=1)\n",
        "y_pred = np.argmax(pred_probs, axis=1)\n",
        "y_true = val_generator.classes\n",
        "\n",
        "# Class names\n",
        "class_names = list(val_generator.class_indices.keys())\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTDyX62pzIVp",
        "outputId": "f5135c54-aa95-4dcf-9161-c971953ea4a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 568ms/step\n",
            "Classification Report:\n",
            "\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "        Bird-drop       0.75      0.59      0.66        41\n",
            "            Clean       0.79      0.79      0.79        42\n",
            "            Dusty       0.64      0.66      0.65        38\n",
            "Electrical-damage       0.90      0.90      0.90        21\n",
            "  Physical-Damage       0.72      0.81      0.76        16\n",
            "     Snow-Covered       0.77      0.96      0.85        24\n",
            "\n",
            "         accuracy                           0.75       182\n",
            "        macro avg       0.76      0.78      0.77       182\n",
            "     weighted avg       0.75      0.75      0.75       182\n",
            "\n",
            "Accuracy: 0.75\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}